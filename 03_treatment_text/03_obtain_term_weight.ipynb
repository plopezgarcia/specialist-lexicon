{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Obtenemos la siguientes medidas:\n",
    "\n",
    "### Obtenemos las siguientes métricas:\n",
    "- P(e|d)\n",
    "- P(d|e)\n",
    "- ICC\n",
    "- TS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_object(path):\n",
    "    pickle_in = open(path,\"rb\")\n",
    "    obj = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    print(\"Cargado el objeto\", path.split(\"/\")[- 1])\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargado el objeto dic_specialties.pkl\n"
     ]
    }
   ],
   "source": [
    "path_dic = 'dic_specialties.pkl'\n",
    "dic_spe = deserialize_object(path_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nº de documentos en la especialidad que NO tienen el n-gram\n",
    "def obtain_ndep(list_doc_term, list_doc_total_spe):\n",
    "    return len(set(set(list_doc_total_spe)-set(list_doc_term)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Et: nº de especialidades que contienen el ngram\n",
    "def obtain_et(term, dic_spe):\n",
    "    et = 0\n",
    "\n",
    "    for specialty, dic in dic_spe.items():\n",
    "        \n",
    "        # obtenemos el diccionario de términos\n",
    "        dic_term = dic['terms']\n",
    "        \n",
    "         # si el término se encuentra en el diccionario sumamos 1\n",
    "        if term in dic_term:\n",
    "            et += 1\n",
    "            \n",
    "    return et      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Número de documentos en las OTRAS especialidades que tienen el n-gram\n",
    "def obtain_ndpe(term, dic_spe, specialty_actual):\n",
    "    \n",
    "    ndpe = 0\n",
    "\n",
    "    for specialty, dic in dic_spe.items():\n",
    "        \n",
    "        # si la especialidad no es la misma\n",
    "        if not specialty == specialty_actual:\n",
    "            \n",
    "            # obtenemos el diccionario de términos\n",
    "            dic_term = dic['terms']\n",
    "            \n",
    "            # si el término se encuentra en el diccionario\n",
    "            if term in dic_term:\n",
    "                \n",
    "                # obtenemos los documentos en los que aparece\n",
    "                doc_term = list(set(dic_term[term]))\n",
    "                \n",
    "                # contamos el nº de documentos y sumamos\n",
    "                ndpe += len(doc_term)\n",
    "                \n",
    "    return ndpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos las veces que se repite el termino en el corpus\n",
    "def obtain_nocc_term(term, dic_spe):\n",
    "    \n",
    "    nocc_term = 0\n",
    "\n",
    "    for specialty, dic in dic_spe.items():\n",
    "        # obtenemos el diccionario de términos\n",
    "        dic_term = dic['terms']\n",
    "\n",
    "        # si el término se encuentra en el diccionario\n",
    "        if term in dic_term:\n",
    "\n",
    "            # obtenemos el nº los documentos en los que aparece\n",
    "            nocc_term += len(dic_term[term])\n",
    "                \n",
    "    return nocc_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-score\n",
    "#Nº de palabras en el corpus: 6469046\n",
    "#Nº de palabras diferentes en el corpus: 115121\n",
    "N = 6469046\n",
    "def obtain_tscore(term, dic_spe):\n",
    "    \n",
    "    # unigramas\n",
    "    if not type(term) is tuple:\n",
    "        nocc_term = obtain_nocc_term(term, dic_spe)\n",
    "        \n",
    "        ts = nocc_term - nocc_term / math.sqrt(nocc_term / N)\n",
    "        \n",
    "        return ts, nocc_term, 0, 0, 0\n",
    "       \n",
    "    else:\n",
    "        # brigramas\n",
    "        if len(term) == 2:\n",
    "            nocc_bigram = obtain_nocc_term(term, dic_spe)\n",
    "            nocc_w1 = obtain_nocc_term(term[0], dic_spe)\n",
    "            nocc_w2 = obtain_nocc_term(term[1], dic_spe)\n",
    "        \n",
    "            ts = nocc_bigram - (nocc_w1 * nocc_w2) / math.sqrt(nocc_bigram / N)\n",
    "            \n",
    "            return ts, nocc_bigram, nocc_w1, nocc_w2, 0\n",
    "            \n",
    "        # trigramas\n",
    "        elif len(term) == 3:\n",
    "            \n",
    "            nocc_trigram = obtain_nocc_term(term, dic_spe)\n",
    "            nocc_w1 = obtain_nocc_term(term[0], dic_spe)\n",
    "            nocc_w2 = obtain_nocc_term(term[1], dic_spe)\n",
    "            nocc_w3 = obtain_nocc_term(term[2], dic_spe)\n",
    "            \n",
    "            ts =  ( nocc_trigram - (nocc_w1 * nocc_w2 * nocc_w3) ) / math.sqrt(nocc_trigram / N)\n",
    "        \n",
    "            return ts, nocc_trigram, nocc_w1, nocc_w2, nocc_w3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Especialidad: H02.403.763.750_gynecology nº docs total: 7732\n",
      "Especialidad: H02.403.225_dermatology nº docs total: 9411\n",
      "Especialidad: H02.403.429.163_cardiology nº docs total: 27316\n",
      "Especialidad: H02.403.740_radiology nº docs total: 2062\n",
      "Especialidad: H02.403.680.600_rehabilitation nº docs total: 2855\n"
     ]
    }
   ],
   "source": [
    "def calculate_weight_terms(dic_spe):\n",
    "    \n",
    "    list_spe_import = ['H02.403.680.600_rehabilitation', 'H02.403.225_dermatology', 'H02.403.763.750_gynecology', 'H02.403.429.163_cardiology', 'H02.403.740_radiology']\n",
    "    for specialty, dic in dic_spe.items():\n",
    "        \n",
    "        if specialty in list_spe_import:\n",
    "            \n",
    "            with open('./term_weight/' +specialty + \"_terms_weight.csv\", \"w\") as fout:\n",
    "                fout.write(\"Término|\")\n",
    "                \n",
    "                fout.write(\"Nº occ esp|\")\n",
    "                \n",
    "                fout.write(\"N(d,e)|\")\n",
    "                fout.write(\"N(d,e')|\")\n",
    "                fout.write(\"N(d',e)|\")\n",
    "                \n",
    "                fout.write(\"Et|\")\n",
    "                \n",
    "                fout.write(\"P(e,d)|\")\n",
    "                fout.write(\"P(d,e)|\")\n",
    "                \n",
    "                fout.write(\"ICC|\")\n",
    "                fout.write(\"T-score|\")\n",
    "                \n",
    "                fout.write(\"P(w1,w2,w3)|\")\n",
    "                fout.write(\"P(w1)|\")\n",
    "                fout.write(\"P(w3)|\")\n",
    "                fout.write(\"P(w2)|\")\n",
    "                \n",
    "                fout.write(\"CorpusWeight|\")\n",
    "                fout.write(\"SpecialtyWeight|\")\n",
    "                \n",
    "                fout.write(\"TotalWeight|\")\n",
    "                fout.write(\"ICC*SpecialtyWeight|\")\n",
    "                \n",
    "                fout.write(\"\\n\")\n",
    "                \n",
    "                list_doc_total_specialty = dic['docs']\n",
    "                dic_terms = dic['terms']\n",
    "\n",
    "                print(\"Especialidad:\", specialty, 'nº docs total:', len(list_doc_total_specialty))\n",
    "                    \n",
    "                for term, list_doc_term in dic_terms.items():\n",
    "                    \n",
    "                    num_ooc_spe = len(list_doc_term)\n",
    "                    \n",
    "                    nde = len(set(list_doc_term))\n",
    "        \n",
    "                    ndep = obtain_ndep(list_doc_term, list_doc_total_specialty)\n",
    "                    ndpe = obtain_ndpe(term, dic_spe, specialty)\n",
    "                    et = obtain_et(term, dic_spe)\n",
    "            \n",
    "                    # p(e|d)\n",
    "                    ped = nde / (nde + ndep)\n",
    "                    \n",
    "                    # p(d|e)\n",
    "                    pde = nde / (nde + ndpe)\n",
    "                   \n",
    "                    # icc\n",
    "                    icc = 1 / ( et + 1) # es el nº de otras especialidades más la q estamos leyendo\n",
    "\n",
    "                    # t-score\n",
    "                    tscore, nocc_term, nocc_w1, nocc_w2, nocc_w3 = obtain_tscore(term, dic_spe)\n",
    "                    \n",
    "                    # corpus level weight\n",
    "                    clw = icc * tscore\n",
    "                    \n",
    "                    # specialty level weight\n",
    "                    slw = ped + pde\n",
    "                    \n",
    "                    # total weight\n",
    "                    tw = clw * slw\n",
    "                    \n",
    "                    # otra prueba (icc x specialty level weight)\n",
    "                    other_total = icc * slw\n",
    "                    \n",
    "                    \n",
    "                    # imprimir en fichero\n",
    "                    fout.write(str(term) + \"|\")\n",
    "                    \n",
    "                    fout.write(str(num_ooc_spe) + \"|\")\n",
    "                    \n",
    "                    fout.write(str(nde) +'|')\n",
    "                    fout.write(str(ndep)+ '|')\n",
    "                    fout.write(str(ndpe) + '|')\n",
    "                    \n",
    "                    fout.write(str(et) + '|')\n",
    "                    \n",
    "                    fout.write(str(ped)+ '|')\n",
    "                    fout.write(str(pde)+ '|')\n",
    "                    \n",
    "                    fout.write(str(icc)+ '|')\n",
    "                    fout.write(str(tscore)+ '|')\n",
    "                    \n",
    "                    fout.write(str(nocc_term)+ '|')\n",
    "                    fout.write(str(nocc_w1)+ '|')\n",
    "                    fout.write(str(nocc_w2)+ '|')\n",
    "                    fout.write(str(nocc_w3)+ '|')\n",
    "                    \n",
    "                    fout.write(str(clw) + \"|\")\n",
    "                    fout.write(str(slw) + \"|\")\n",
    "                \n",
    "                    fout.write(str(tw) + \"|\")\n",
    "                    fout.write(str(other_total) + \"|\")\n",
    "                \n",
    "                    fout.write('\\n')\n",
    "                \n",
    "calculate_weight_terms(dic_spe)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
